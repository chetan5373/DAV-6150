{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b15771",
   "metadata": {},
   "source": [
    "### <CENTER><h1><u>Classification via KNN & SVM</u></CENTER></h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<CENTER>(TEAM CONTRIBUTORS: CHAITANYA DEVARSHI, SHASHANK SHEKHAR, BITTERLEIN KONNOTH BIJU)</CENTER>\n",
    "\n",
    "----\n",
    "\n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb4f209",
   "metadata": {},
   "source": [
    "<h2><u>Content</u></h2>\n",
    "\n",
    "1. [Introduction](#1.-Introduction)\n",
    "\n",
    "  1.1 [Problem Statement](#1.1-Problem-Statement)\n",
    "  \n",
    "  1.2 [Methodology](#1.2-Methodology)\n",
    "  \n",
    "\n",
    "2. [Data Loading & Preparation](#2.-Data-Loading-&-Preparation)\n",
    "\n",
    "  2.1 [Read the Data](#2.1-Read-the-Data)\n",
    "  \n",
    "\n",
    "3. [EDA](#3.-Exploratory-Data-Analysis)\n",
    "\n",
    "  3.1 [Missing Values](#3.1-Missing-Values)\n",
    "  \n",
    "  3.2 [Univariate](#3.2-Univariate-Analysis)\n",
    "  \n",
    "   - 3.2.1 [For numeric features](#3.2.1-Univariate-Analysis-for-numeric-features)\n",
    "     \n",
    "   - 3.2.2 [For Binary features](#3.2.2-Univariate-Analysis-for-Binary-features)\n",
    "     \n",
    "  3.3 [Bivariate](#3.3-Bivariate-Analysis)\n",
    "  \n",
    "  3.4 [Multivariate](#3.4-Multivariate-Analysis)\n",
    "\n",
    "\n",
    "4. [Data Cleaning](#4.-Data-Cleaning)\n",
    "\n",
    "  4.1 [Handling Outliers](#4.1-Handling-Outliers)\n",
    "\n",
    "  4.2 [Handling Skewness](#4.2-Handling-Skewness)\n",
    "\n",
    "\n",
    "5. [Prepped Data Review](#5.-Prepped-Data-Review)\n",
    "\n",
    "\n",
    "6. [Dimensionality Reduction](#6.-Dimensionality-Reduction)\n",
    "\n",
    "  6.1 [Variance Threshold](#6.1-Variance-Threshold)\n",
    "  \n",
    "  6.2 [Forward Elimination](#6.2-Forward-Elimination)\n",
    "\n",
    "\n",
    "7. [Binary Logistic Regression Models](#7.-Binary-Logistic-Regression-Models)\n",
    "\n",
    "  7.1 [1<sup>st</sup> Model](#7.1-1st-Model)\n",
    "  \n",
    "  7.2 [2<sup>nd</sup> Model](#7.2-2nd-Model)\n",
    "  \n",
    "  7.3 [3<sup>rd</sup> Model](#7.3-3rd-Model)\n",
    "  \n",
    "  \n",
    "8. [Model Selection](#8.-Model-Selection)\n",
    "\n",
    "\n",
    "9. [Conclusion](#Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169aafd8",
   "metadata": {},
   "source": [
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228ca2b",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d6ae3",
   "metadata": {},
   "source": [
    "Like many industries, the insurance industry is always interested in broadening its relationships with existing customers. To that end, insurance companies will often attempt to sell additional products to their existing customers. For example, if you have a homeowner’s policy with a particular insurance company, they will likely try to also sell you an auto insurance policy, or perhaps a water damage supplemental policy to your homeowner’s policy, etc.\n",
    "\n",
    "\n",
    "__Dataset Description__\n",
    "\n",
    "The data set we will be using is sourced from a Kaggle contribution. The data set is comprised of more than 14,000 observations of 1 response/dependent variable (which indicates whether or not the new insurance product was purchased) and 14 explanatory/independent variables. The insurance company gathered data about customers to whom they offered the new product.\n",
    "We are given information about whether they did or did not sign up for the new product, together with some customer information and information about their buying behavior of two other products.\n",
    "\n",
    "A data dictionary for the dataset is provided below.\n",
    "\n",
    "|Attribute  |Description          |\n",
    "|-----------|---------------------|\n",
    "|ID         |Unique customer identifier|\n",
    "|TARGET     |Indicator of customer buying the new product (N = no, Y = yes)|\n",
    "|Loyalty    |Customer loyalty level, from low to high (0 to 3), 99 = unclassified|\n",
    "|Age        |Customer age in years|\n",
    "|City       |Unique code per city (where the customer resides)|\n",
    "|Age_p      |Age of customer’s partner in years|\n",
    "|LOR        |Length of Relationship in years|\n",
    "|LOR_m      |Length of customer’s relationship with company (in months)|\n",
    "|Prod_A     |Customer previously bought Product A (0=no, 1=yes)|\n",
    "|Type_A     |Type of product A|\n",
    "|Turnover_A |Amount of money customer spent on Product A|\n",
    "|Prod_B     |Customer previously bought Product B (0=no, 1=yes)|\n",
    "|Type_B     |Type of product B|\n",
    "|Turnover_B |Amount of money customer spent on Product B|\n",
    "|Contract   |Type of contract|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c4028",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604bcb5b",
   "metadata": {},
   "source": [
    "## 1.1 Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b866d",
   "metadata": {},
   "source": [
    "A large insurance company has given us a task with the development of a model that can predict whether or not a given existing customer is likely to purchase an additional insurance product from the company. The insurance company plans to use the output of such a model in an attempt to improve its customer retention and sales practices.By delving into a dataset containing various customer-related variables, we seek to unravel patterns and relationships that shed light on the factors influencing consumer decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79564c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6d87f",
   "metadata": {},
   "source": [
    "## 1.2 Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c06f9",
   "metadata": {},
   "source": [
    "<h3><u> To address this assignment, we will follow these below steps :- </u></h3>\n",
    "\n",
    "1. **Load the dataset**: Upload the `M7_Data.csv` file from the DAV 6150 Github Repository.\n",
    "\n",
    "2. **Read the dataset**: Using a Jupyter Notebook, read the dataset from the respective Github repository and load it into a Pandas DataFrame.\n",
    "\n",
    "3. **Perform EDA**: Carry out Exploratory Data Analysis to examine the dataset's structure and understand the variables.\n",
    "\n",
    "4. **Identify and rectify issues**: Detect data quality and integrity issues such as missing values or outliers during EDA, and take appropriate actions to address them.\n",
    "\n",
    "5. **Prepped Data Review**: Here, we will cross check every thing and will make sure our data is ready for further analysis.\n",
    "\n",
    "6. **Feature Scale, Selection & Dimensionality Reduction**: Applying feature selection techniques and perform dimensionality reduction to prepare the data for modeling.\n",
    "\n",
    "7. **Binary Logistic Regression Modelling**: We will make 3 different models of Binary Logistic Regression.\n",
    "\n",
    "8. **Models Selection**: Among the 3 different models, we will make our judgement on selecting one model.\n",
    "\n",
    "9. **Conclusion**: We will conclude our work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9b98a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13641919",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22858488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basic Libraries.\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Importing Libraries for statistical analysis.\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# Importing Libraries for machine learning models.\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import imblearn\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Importing Libraries for plotting the graphs.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing Libraries for Standarising and Normalising.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import Library for PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import missingno library for checking on missing values.\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "# Importing train_test_split .\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "# Importing Libraries for Forward elemination.\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importing filterwarnings from warnings to ignore warnings.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26aaf1",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a87a00",
   "metadata": {},
   "source": [
    "### 2.1 Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cc46d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-93eaf1d92d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     }\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0minsurance_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/Shashank4075/DAV-6150/refs/heads/main/M7_Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Reorder the DataFrame columns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Loading the data from the github repository DAV-6150.\n",
    "\n",
    "# Based on Domain knowledge assigning a proper data types to the columns while loading the data.\n",
    "column_types = {        \n",
    "        'TARGET': object,    \n",
    "        'loyalty': object,\n",
    "        'ID': 'int64',\n",
    "        'age': 'int64',\n",
    "        'city': object,\n",
    "        'LOR': 'int64',    \n",
    "        'prod_A': object,\n",
    "        'type_A': object,\n",
    "        'type_B': object,\n",
    "        'prod_B': object,    \n",
    "        'turnover_A': float,\n",
    "        'turnover_B': float,\n",
    "        'contract': object,\n",
    "        'age_P': 'int64',\n",
    "        'lor_M': 'int64'  \n",
    "    }\n",
    "\n",
    "insurance_data = pd.read_csv(\"https://raw.githubusercontent.com/Shashank4075/DAV-6150/refs/heads/main/M7_Data.csv\")\n",
    "\n",
    "# Reorder the DataFrame columns. \n",
    "insurance_data = insurance_data[['TARGET', 'loyalty', 'ID', 'city', 'prod_A', 'type_A', 'type_B', 'prod_B', 'contract', \n",
    "                   'age', 'age_P', 'lor_M', 'LOR', 'turnover_A', 'turnover_B']]\n",
    "\n",
    "# Making a copy of the dataset.\n",
    "df = insurance_data.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0374d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying how many rows and columns the dataframe consist of.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ed323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a concise summary of the DataFrame .\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e537241",
   "metadata": {},
   "source": [
    "**Dataset observation:**\n",
    "\n",
    "\n",
    "\n",
    "- Index ranges from 0-14015.\n",
    "\n",
    "- Total number of attributes are 15.\n",
    "\n",
    "- Where, 12 are 'int', 2 are 'float' and 1 is 'object'.\n",
    "\n",
    "- As of now there are no any missing values in any columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c179ea8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc136515",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd3323",
   "metadata": {},
   "source": [
    "- Analyzing a data set for purposes of summarizing its characteristics, identifying relationships between its attributes, and discovering patterns, trends, outliers, missing values and invalid values within the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c36356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking columns names.\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c3c2bd",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aec04b",
   "metadata": {},
   "source": [
    "### 3.1 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fe7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values.\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11209bad",
   "metadata": {},
   "source": [
    "- As of now there are no nulls present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb53216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the duplicate columns.\n",
    "\n",
    "count_duplicate = df.duplicated().sum()\n",
    "\n",
    "print(f\"Number of duplicate rows :\",count_duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869d893",
   "metadata": {},
   "source": [
    "- There are 3008 duplicate rows in the whole dataset, it should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a941360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicate rows.\n",
    "\n",
    "df = df[df.duplicated() == False]\n",
    "\n",
    "# Checking the shape after removing the duplicate rows.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3696bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any negative value exists in the entire DataFrame.\n",
    "\n",
    "# Select only numeric columns.\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Find columns that have negative values.\n",
    "columns_with_negatives = numeric_df.columns[(numeric_df < 0).any()]\n",
    "\n",
    "if (numeric_df < 0).any().any():\n",
    "    print(\"There are negative values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no negative values in the DataFrame.\")\n",
    "    \n",
    "# Print the column names that contain negative values.\n",
    "print(\"Columns with negative values:\", columns_with_negatives.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d04c0",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf291d",
   "metadata": {},
   "source": [
    "### 3.2 Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407053f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35388784",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a3716",
   "metadata": {},
   "source": [
    "### 3.2.1 For Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa512cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to plot dist and box plot for all the numeric features. \n",
    "\n",
    "def box_dist_plot(df , column):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    This function is to plot box-plot and distribution-plot for a given column, \n",
    "    column's median value, with count and percentage of null values. \n",
    "    \n",
    "    Parameters :-\n",
    "        df : Dataframe           # df contains Dataframe.\n",
    "        column : str             # Column name which is to be ploted.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.style.use('ggplot')  \n",
    "    \n",
    "    plt.figure(figsize=(18, 7))\n",
    "\n",
    "    # Box plot.\n",
    "    plt.subplot(121)\n",
    "    sns.boxplot(y = df[column])  # Create box plot\n",
    "    plt.title(f'Box Plot of : {column}')\n",
    "\n",
    "    # Distribution plot.\n",
    "    plt.subplot(122)\n",
    "    sns.histplot(df[column], bins=30, kde=True)  # Create histogram with KDE\n",
    "    plt.title(f'Distribution Plot of : {column}')\n",
    "\n",
    "    # Adjusting the layout.\n",
    "    plt.tight_layout() \n",
    "\n",
    "    plt.show()  \n",
    "\n",
    "    # To print statistics.\n",
    "    print(df[column].describe())\n",
    "    print('Median :', df[column].median())\n",
    "    print()\n",
    "    print('Total Number of null values :', df[column].isnull().sum(), 'count,', \n",
    "          round(df[column].isnull().mean() * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587da338",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dist_plot(df,'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211f0b9",
   "metadata": {},
   "source": [
    "- Here 'age' is the age of customers in years, data is right skewed and also it has an outliers, but they are valid data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dist_plot(df,'age_P')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1373a",
   "metadata": {},
   "source": [
    "- Here 'age_P' represents age of customers' partner in years, where data is right skewed and has a outliers. Thus, all the data points are valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a98950",
   "metadata": {},
   "source": [
    "__Note__ - As per the above 2 univariate analysis of 'age' and 'age_P', has exactly the same statistic value, will check if each data points are same in both the attributes, then we can drop one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0097d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "box_dist_plot(df,'LOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4f1dae",
   "metadata": {},
   "source": [
    "- Here 'LOR', it is the length of relationship in years with the insurance company, mostly the data of relationship with the insurance company is 0 - 2 years, so there are outliers but are valid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dist_plot(df,'lor_M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613a582",
   "metadata": {},
   "source": [
    "- Here 'lor_M' it is the length of relationship in months with the insurance company, mostly the data of relationship with the insurance company is 0 - 30 months, so there are outliers but are valid points. By the way, this attribute is similar to the 'LOR' attributes in terms of observation, may be from both we can exclude one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dist_plot(df,'turnover_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1025614",
   "metadata": {},
   "source": [
    "- Here 'turnover_A', it is a turnover of the sell of product-A, where highest turnover is around 5500 and lowest is around 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0abe5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dist_plot(df,'turnover_B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4883501",
   "metadata": {},
   "source": [
    "- Here 'turnover_B', it is a turnover of the sell of product-B, where highest turnover is around 12250 and lowest is around 190."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1729a8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fab05",
   "metadata": {},
   "source": [
    "### 3.2.2 For Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adbd1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a count plot and displays the count of each category for a specified column in the dataframe.\n",
    "\n",
    "def plot_category_counts(df, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function to plot a countplot and  displays the count of each category \n",
    "    for a specified column in the dataframe.\n",
    "    \n",
    "        column : str\n",
    "        The name of the categorical column to plot and count.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count plot for the specified column.\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x=column, palette=\"viridis\")\n",
    "    \n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel(column)  \n",
    "    plt.ylabel('Count')     \n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.title(f'Count of {column}')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Display count of each category\n",
    "    counts = df[column].value_counts()\n",
    "    print(f\"\\nCounts for {column}:\\n{counts}\")\n",
    "\n",
    "    #For unique count of input\n",
    "    unique_count = df[column].nunique()\n",
    "    print(f\"\\nUnique for {column}:\\n{unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155800b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df, 'TARGET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649fa0ef",
   "metadata": {},
   "source": [
    "- There are 'Yes' values around 6016 and 8000 values of 'No' in our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'loyalty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33dc5c",
   "metadata": {},
   "source": [
    "- It is the level of loyalty from low to high (0 to 3), and 99 indicates unclassified values, there are lot of unclassified values which we don't need to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c891d01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'city')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08d34e",
   "metadata": {},
   "source": [
    "- As per the countplot, we can observe that most of the data is of one particular class. So, we will be checking the percentage of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8816d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculating the percentage of the attribute 'city's unique values.\n",
    "\n",
    "(df.city.value_counts()/len(df.city)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68de41",
   "metadata": {},
   "source": [
    "- As most of the data lies in 2, which means that 97.88% of the data is of the city-2. So, this particular city attribute is not of much use in training the models, we can get rid of this attribute.\n",
    "- This also reflects that our dataset is bias to one particular city (city-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd24cb8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'prod_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c7c4b",
   "metadata": {},
   "source": [
    "- Here it shows the count of product-A is bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89850f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'type_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df850ac8",
   "metadata": {},
   "source": [
    "- Here it shows the count of each type of product-A, there are total 3 types of product-A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'type_B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa89d5",
   "metadata": {},
   "source": [
    "- Here it shows the count of each type of product-B, there are total 4 types of product-B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009085d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'prod_B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e04d95",
   "metadata": {},
   "source": [
    "- Here it shows the count of product-B which is purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'contract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b373c65",
   "metadata": {},
   "source": [
    "- Here it is the count of contracts, but here is only one type of contract. So, it will not of our use, and furtherly we can get rid of it.\n",
    "- We can say that our dataset only of contract type-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2096ab",
   "metadata": {},
   "source": [
    "__Note__ - 'ID' attribute is unique identifier which has no role in model training so we will be excluding it under data cleaning, that is why we are not ploting anything for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b404d3",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78462a22",
   "metadata": {},
   "source": [
    "### 3.3 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'prod_A']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='prod_A', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and  Product of A')\n",
    "plt.legend(title='prod_A')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09292aae",
   "metadata": {},
   "source": [
    "- Product A bought by customers are more when the response value is 'N' as compared to when the response column is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'type_A']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='type_A', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and Type of Product of A')\n",
    "plt.legend(title='type_A')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0d4f2",
   "metadata": {},
   "source": [
    "- Type of Product A (\"3\") counts are more when the response value is 'N' as compared to when reponse value is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'prod_B']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='prod_B', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and  Product of B')\n",
    "plt.legend(title='prod_B')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d952665",
   "metadata": {},
   "source": [
    "- Product B bought by customers is more when the response value is 'N' as compared to when the response value is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'type_B']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='type_B', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and Type of Product of B')\n",
    "plt.legend(title='type_B')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddaa94e",
   "metadata": {},
   "source": [
    "- Type of Product B ('3') count is more when the response value is 'N' as compared to when the response value is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8230d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the fuction to plot bargraph between Categorical and numerical columns or Categorical to Categorical.\n",
    "\n",
    "def plot_bar(df, x_col, y_col, title=\"Bar Plot\", x_label=None, y_label=None, color='c', \n",
    "             size=(10, 6), rotate_xticks=True, xticks_rotation=45): \n",
    "    \n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=size)\n",
    "    sns.barplot(x=x_col, y=y_col, data=df, color=color)\n",
    "\n",
    "    # Set the title and axis labels\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(x_label if x_label else x_col, fontsize=14)\n",
    "    plt.ylabel(y_label if y_label else y_col, fontsize=14)\n",
    "    \n",
    "#  rotate x-axis labels\n",
    "\n",
    "    if rotate_xticks:\n",
    "        plt.xticks(rotation=90, ha='right')\n",
    "    \n",
    "# Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cfd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function to plot bargraph\n",
    "\n",
    "plot_bar(df, 'TARGET', 'turnover_A', title=\"TARGET  vs Turnover of A  \", x_label=\"TARGET\", y_label=\"turnover_A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83771fb6",
   "metadata": {},
   "source": [
    "-  The graph shows that customers that purchased the new product(as indicated by Target =1 ) have spent more Product A than the customers that choose not to purchase the new product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function to plot bargraph\n",
    "\n",
    "plot_bar(df, 'TARGET', 'turnover_B', title=\"TARGET  vs Turnover of B  \", x_label=\"TARGET\", y_label=\"turnover_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba831a0",
   "metadata": {},
   "source": [
    "-  The graph shows that customers that not  purchased the new product(as indicated by Target =N ) have spent more Product B than the customers that choose  to purchase the new product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function to plot bargraph\n",
    "\n",
    "plot_bar(df, 'loyalty', 'turnover_A', title=\"loyalty  vs Turnover of A  \", x_label=\"loyalty\", y_label=\"turnover_A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac56ac2",
   "metadata": {},
   "source": [
    "- Turnover A of Product A is most when the loyality is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function to plot bargraph.\n",
    "\n",
    "plot_bar(df, 'loyalty', 'LOR', title=\"loyalty  vs Length of relationship  \", x_label=\"loyalty\", y_label=\"LOR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907dc53",
   "metadata": {},
   "source": [
    "- loyality is 1 when there is highest Length of Relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to plot bargraph\n",
    "\n",
    "plot_bar(df, 'loyalty', 'turnover_B', title=\"loyalty  vs Turnover of B \", x_label=\"loyalty\", y_label=\"turnover_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee8335",
   "metadata": {},
   "source": [
    "- Turnover of Product B is most when the loyality is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd72ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'loyalty']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='loyalty', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and loyalty')\n",
    "plt.legend(title='loyalty')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6422f13b",
   "metadata": {},
   "source": [
    "- In both cases number of non specified('99') loyality is maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['prod_A', 'type_A']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='prod_A', y='counts', hue='type_A', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('prod_A')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of Product A and Type of Product A')\n",
    "plt.legend(title='type_A')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31755829",
   "metadata": {},
   "source": [
    "- In Product A maximum number of product type A bought is '3' and not bought is '0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['prod_B', 'type_B']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='prod_B', y='counts', hue='type_B', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('prod_B')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of Product B and Type of Product B')\n",
    "plt.legend(title='type_B')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07349b",
   "metadata": {},
   "source": [
    "-  In Product B maximum number of product type B bought is '3' and not bought is '0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scatterplot  to find the insight \n",
    "\n",
    "sns.scatterplot(x='age', y='LOR' ,data=df, color='c')  \n",
    "plt.title('Scatter Plot:Age  vs Lenght of Relationship')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd91664",
   "metadata": {},
   "source": [
    "- Both the columns is strongly correlated to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8b2a3",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c7b20e",
   "metadata": {},
   "source": [
    "### 3.4 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('TARGET')[['age', 'LOR']].mean()\n",
    "\n",
    "# Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by TARGET')\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d39e5",
   "metadata": {},
   "source": [
    "- Average value of age is less and average value of length of relationship is more when the response variable is \"N\".\n",
    "- Average value of age is more and average value of length of relationship is less when the response variable is \"Y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('TARGET')[['turnover_A','turnover_B','age','LOR']].mean()\n",
    "\n",
    "# Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by Target')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf989f2",
   "metadata": {},
   "source": [
    "- When the Target column has 0 input or the product is not purchased then the duration of relationship is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fe007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('prod_A')[['turnover_A','age','LOR']].mean()\n",
    "\n",
    "# Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by Product A')\n",
    "plt.xlabel('Product A')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060e6b9",
   "metadata": {},
   "source": [
    "- When the product A is purchased the average duration of relationship is high.\n",
    "- When the product A is not purchased the average of age is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('prod_B')[['turnover_B','age','LOR']].mean()\n",
    "\n",
    "# Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by Product B')\n",
    "plt.xlabel('Product B')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f85ed",
   "metadata": {},
   "source": [
    "- When the product B is purchased the average duration of relationship is high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855a40d",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6445c",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ad905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each columns.\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550aecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lambda function converts 'Y' to 1 and any other value to 0 on 'Target' attribute.\n",
    "\n",
    "df['TARGET'] = df['TARGET'].apply(lambda x: 1 if x == 'Y' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2606ce3",
   "metadata": {},
   "source": [
    "- Converting the 'Y' & 'N' to '1' & '0' of response variable('TARGET'), for better analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7db6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'Target'.\n",
    "\n",
    "df.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13253940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the unwanted attributes, which has been traced from the univariate analysis.\n",
    "\n",
    "df = df.drop(columns=['ID', 'contract', 'city'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ed52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the each data points of 'age' & 'age_P', as mentioned earlier in the note from univariate analysis.\n",
    "\n",
    "a = 0\n",
    "p = 0\n",
    "\n",
    "for i in range(len(df.age)):\n",
    "    if df.age[i] == df.age_P[i]:\n",
    "        a += 1\n",
    "    else:\n",
    "        p += 1\n",
    "\n",
    "print(a)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48df53c",
   "metadata": {},
   "source": [
    "- So, here both the attributes are eaxctly the same value in each cells. So, we will be removing 'age_P'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'age_P' attribute.\n",
    "\n",
    "df = df.drop(columns=['age_P'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16266ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'lor_M' as detected from the bivariate analysis that - the correlation of LOR and lor_M is 1, \n",
    "# which means that they both have very strong correlation and provides similar information, only difference is that\n",
    "# one entity is in years and other is in months. So, we can remove either of it.\n",
    "\n",
    "df = df.drop(columns=['lor_M'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2c346",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320bdc8c",
   "metadata": {},
   "source": [
    "### 4.1 Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting only numeric columns, except 'LOR'.\n",
    "numeric_cols = ['age', 'LOR', 'turnover_A', 'turnover_B']\n",
    "\n",
    "# Looping through numeric columns to get the lower and upper bound values.  \n",
    "for col in numeric_cols:\n",
    "    q1 = np.quantile(df[col], 0.25)\n",
    "    q3 = np.quantile(df[col], 0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + (1.2 * iqr)                  # Multiplying by 1.2 to not get the values in negative.\n",
    "    lower_bound = q1 - (1.2 * iqr)\n",
    "    range = [lower_bound, upper_bound]\n",
    "    print(f\"range in {col}:\",range)\n",
    "    \n",
    "    # checking the maximum value \n",
    "    max_value = df[col].max()\n",
    "    print(f\"The maximum value in {col} is: {max_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc6c30",
   "metadata": {},
   "source": [
    "- From this, we can observe that the maximum values of  features such as age, LOR, turnover_A, and turnover_B  they are higher than upper bound values it should be potential outliers. However, we  believe  the numbers are acceptable and valid. For example:  12,249  is a valid value for turnover_B and also in age maximum value  can be 102. So, we retain the values for better analysis.\n",
    "\n",
    "- Reference: https://medium.com/@akashmishra77/box-plots-detect-and-remove-outliers-from-distribution-a124ee88cf3e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097adb8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c1c5a",
   "metadata": {},
   "source": [
    "### 4.2 Handling Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb83f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for negative value.\n",
    "\n",
    "numeric_cols = ['age', 'LOR', 'turnover_A', 'turnover_B']\n",
    "\n",
    "negative_check = df[numeric_cols].apply(lambda x: (x < 0).any())\n",
    "\n",
    "print(negative_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23c783",
   "metadata": {},
   "source": [
    "- All numeric attributes are non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc967f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for zero values.\n",
    "\n",
    "zero_check = df[numeric_cols].apply(lambda x: (x == 0).any())\n",
    "\n",
    "print(zero_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5485e31",
   "metadata": {},
   "source": [
    "- Except LOR all features above don't have zero value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de841736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying  Box-Cox transformation to each numeric columns for handeling the skewness.\n",
    "\n",
    "for col in numeric_cols:\n",
    "    \n",
    "    # Increasing  values by 1 to handle zeros\n",
    "    df[col] += 1\n",
    "    \n",
    "    # Performing Box-Cox transformation and save the lambda value\n",
    "    fitted_data, fitted_lambda = stats.boxcox(df[col])\n",
    "    \n",
    "    # Replacing original column with transformed data\n",
    "    df[col] = fitted_data\n",
    "    \n",
    "    #  Print lambda value for each column\n",
    "    print(f\"Lambda value for {col}: {fitted_lambda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9b35c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c2ae4",
   "metadata": {},
   "source": [
    "## 5. Prepped Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d825a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkig the cleaned dataframe.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the df.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7090b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking every columns has the correct data types.\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb46d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the descriptive statistics.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that there are no duplicates.\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05961a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring that there is no null value present.\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f26dbd",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8aa6d",
   "metadata": {},
   "source": [
    "#### Ensuring Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cde38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "box_dist_plot(df, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72106010",
   "metadata": {},
   "source": [
    "- Age column still has outliers but it is valid data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25882778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "box_dist_plot(df, 'LOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abcd51",
   "metadata": {},
   "source": [
    "- LOR column still has outlier but it is valid data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2b3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "box_dist_plot(df, 'turnover_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aceefd6",
   "metadata": {},
   "source": [
    "- Turnover A column still has outliers but it is valid data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e9089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "box_dist_plot(df, 'turnover_B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441efa5",
   "metadata": {},
   "source": [
    "- Turnover B column still has outliers but it is valid data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d31e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'TARGET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd0bad",
   "metadata": {},
   "source": [
    "- Count of negative buying is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426165a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'loyalty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c49ec",
   "metadata": {},
   "source": [
    "- Count of unspecified loyalty is maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8321d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'prod_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda0fe8",
   "metadata": {},
   "source": [
    "- Count of buying product A is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a1867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'type_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e63667",
   "metadata": {},
   "source": [
    "- Count of buying product of type A (3) is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'prod_B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275b79a",
   "metadata": {},
   "source": [
    "- Count of buying product B is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "plot_category_counts(df,'type_B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1d60f",
   "metadata": {},
   "source": [
    "-  Count of buying product B of type B(3) is maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9ffc7",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaed7ab",
   "metadata": {},
   "source": [
    "#### Ensuring Bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4ee7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'prod_A']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='prod_A', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and  Product of A')\n",
    "plt.legend(title='prod_A')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b80f2",
   "metadata": {},
   "source": [
    "- Product A bought by customers is more when the response value is 'N' as compared to when the response column is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10703edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'type_A']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='type_A', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and Type of Product of A')\n",
    "plt.legend(title='type_A')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b104203",
   "metadata": {},
   "source": [
    "- Type of Product A (\"3\") count is more when the response value is 'N' as compared to when reponse value is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f9a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'prod_B']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='prod_B', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and  Product of B')\n",
    "plt.legend(title='prod_B')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca93d9e",
   "metadata": {},
   "source": [
    "-  Product B bought by customers is more when the reponse value is 'N' as compared to when the response value is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695cd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['TARGET', 'type_B']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TARGET', y='counts', hue='type_B', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of TARGET and Type of Product of B')\n",
    "plt.legend(title='type_B')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7d2166",
   "metadata": {},
   "source": [
    "- Type of Product B ('3') count  is more when the response value is 'N' as compared to when the response value is 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the fuction to plot bargraph between Categorical and numerical columns or Categorical to Categorical.\n",
    "\n",
    "def plot_bar(df, x_col, y_col, title=\"Bar Plot\", x_label=None, y_label=None, color='b', size=(10, 6), rotate_xticks=True, xticks_rotation=45):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=size)\n",
    "    sns.barplot(x=x_col, y=y_col, data=df, color=color)\n",
    "\n",
    "    # Set the title and axis labels\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(x_label if x_label else x_col, fontsize=14)\n",
    "    plt.ylabel(y_label if y_label else y_col, fontsize=14)\n",
    "    \n",
    "#  rotate x-axis labels\n",
    " \n",
    "    if rotate_xticks:\n",
    "        plt.xticks(rotation=90, ha='right')\n",
    "    \n",
    "# Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d63e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function to plot bargraph\n",
    "\n",
    "plot_bar(df, 'TARGET', 'turnover_A', title=\"TARGET  vs Turnover of A  \", x_label=\"TARGET\", y_label=\"turnover_A\", color='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd6da6",
   "metadata": {},
   "source": [
    "- The graph shows that customers that purchased the new product(as indicated by Target =1 ) have spent more Product A than the customers that choose not to purchase the new product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function to plot bargraph\n",
    "\n",
    "plot_bar(df, 'TARGET', 'turnover_B', title=\"TARGET  vs Turnover of B  \", x_label=\"TARGET\", y_label=\"turnover_B\", color='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65b209",
   "metadata": {},
   "source": [
    "- The graph shows that customers that purchased the new product(as indicated by Target =1 ) have spent more Product B than the customers that choose not to purchase the new product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d923400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['prod_A', 'type_A']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='prod_A', y='counts', hue='type_A', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('prod_A')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of Product A and Type of Product A')\n",
    "plt.legend(title='type_A')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2e0cb",
   "metadata": {},
   "source": [
    "- Product A bought is more when the type of product is '3' and not bought is more when the product type is '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e675668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the values for each combination of categorical column.\n",
    "count_data = df.groupby(['prod_B', 'type_B']).size().reset_index(name='counts')\n",
    "\n",
    "# Grouped bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='prod_B', y='counts', hue='type_B', data=count_data, palette='viridis')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('prod_B')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Grouped Bar Plot of Product B and Type of Product B')\n",
    "plt.legend(title='type_B')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b577e",
   "metadata": {},
   "source": [
    "-  Product B bought is more when the type of product  is '3' and not bought is more when the product type is '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c23c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Scatterplot  to find the insight \n",
    "\n",
    "sns.scatterplot(x='age', y='LOR' ,data=df, color='c')  # code to plot bargraph\n",
    "plt.title('Scatter Plot:Age  vs Lenght of Relationship')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe28e1d6",
   "metadata": {},
   "source": [
    "- Both the columns is strongly correlated to each other.\n",
    "- It might indicate a relationship where changes in one variable can be used to reliably predict changes in the other variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c2189",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb7702",
   "metadata": {},
   "source": [
    "#### Ensuring Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e32fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Average Count the values for each combination of categorical column and numerical column.\n",
    "# Step 1: Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('TARGET')[['age', 'LOR']].mean()\n",
    "\n",
    "# Step 2: Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by TARGET')\n",
    "plt.xlabel('TARGET')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)  # Keep the x-axis labels horizontal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e508d",
   "metadata": {},
   "source": [
    "- Average value of age is less and average value of length of relationship is more when the response variable is \"N\".\n",
    "- Average value of age is more and average value of length of relationship is less when the response variable is \"Y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc68ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Average Count the values for each combination of categorical column and numerical column.\n",
    "\n",
    "# Step 1: Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('TARGET')[['turnover_A','turnover_B','age','LOR']].mean()\n",
    "\n",
    "# Step 2: Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by Target')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)  # Keep the x-axis labels horizontal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42249e9e",
   "metadata": {},
   "source": [
    "-  When the Target column has 0 input or the product is not purchased then the average duration of relationship is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0411ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Average Count the values for each combination of categorical column and numerical column.\n",
    "\n",
    "# Step 1: Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('prod_A')[['turnover_A','age','LOR']].mean()\n",
    "\n",
    "# Step 2: Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by Product A')\n",
    "plt.xlabel('Product A')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)  # Keep the x-axis labels horizontal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a0d2d",
   "metadata": {},
   "source": [
    "- When the product A is purchased the average duration of relationship is high.\n",
    "- When the product A is not purchased the average of age is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39207032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Count the values for each combination of categorical column and numerical column.\n",
    "\n",
    "# Step 1: Calculate the average of selected columns grouped by the binary column\n",
    "averages = df.groupby('prod_B')[['turnover_B','age','LOR']].mean()\n",
    "\n",
    "# Step 2: Plot the averages using a barplot\n",
    "averages.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Average of Columns Grouped by Product B')\n",
    "plt.xlabel('Product B')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)  # Keep the x-axis labels horizontal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25562ced",
   "metadata": {},
   "source": [
    "- When the product B is purchased the average duration of relationship is high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa92b1ac",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3a870",
   "metadata": {},
   "source": [
    "## 6. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9865793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-anlysising 'loyalty' column.\n",
    "\n",
    "print(df['loyalty'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb657ff3",
   "metadata": {},
   "source": [
    "- We will remove the loyalty column as it has 45% unclassified data, and it is type of ordinal data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ded6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'loyalty' from df.\n",
    "\n",
    "df = df.drop(columns=['loyalty'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6127d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating 'TARGET' attribute from rest of the attributes, as it is the response variable.\n",
    "\n",
    "y = df['TARGET']\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50390eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'TARGET' column.\n",
    "\n",
    "X = df.drop('TARGET', axis=1)\n",
    "\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the 'type_A' & 'type_B' unique values to identify clearly.\n",
    "\n",
    "# Changing 'type_A' unique values to 1,3,&5 first three odd numbers.\n",
    "X['type_A'] = X['type_A'].replace({0: 1, 3: 3, 6: 5})\n",
    "print(X.type_A.unique())\n",
    "\n",
    "\n",
    "# Changing 'type_B' unique values to 2,4,6,&8 first four even numbers.\n",
    "X['type_B'] = X['type_B'].replace({0: 2, 3: 4, 6: 6, 9: 8})\n",
    "print(X.type_B.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dummy data from the categorical columns.\n",
    "cat_cols = ['prod_A', 'type_A', 'prod_B', 'type_B']\n",
    "\n",
    "# Converting the categorical columns to object type.\n",
    "X[cat_cols] = X[cat_cols].astype('object')\n",
    "\n",
    "\n",
    "X_cat_dummy = pd.get_dummies(X[cat_cols], drop_first=True).astype(int)\n",
    "\n",
    "X_cat_dummy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original columns from the DataFrame.\n",
    "\n",
    "X.drop(columns=cat_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarise the numeric attributes.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "X_std = std_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the nd array of X_std to a DataFrame with the desired column names\n",
    "X_std = pd.DataFrame(X_std, columns=['age', 'LOR', 'turnover_A', 'turnover_B'])\n",
    "\n",
    "# Optional: View the first few rows to ensure the data is correctly formatted\n",
    "print(X_std.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f04123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the original DataFrame with the one-hot encoded columns with the numeric standarised data.\n",
    "\n",
    "X = pd.concat([X_std, X_cat_dummy], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3767792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of dataframe having independent attributes.\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd353c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train & test split.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the resulting datasets.\n",
    "\n",
    "print(\"Training dataset shapes ->  X: {}, y: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing dataset shapes  ->  X: {}, y: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc5eed",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc183c9",
   "metadata": {},
   "source": [
    "### 6.1 Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the VarianceThreshold object (remove features with variance below the threshold)\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "# Fit the selector to the data\n",
    "selector.fit(X_train)\n",
    "\n",
    "selector.get_support()\n",
    "\n",
    "# Get the list of featurs with low variance.\n",
    "low_var_cols = [col for col in X.columns if col not in X.columns[selector.get_support()]]\n",
    "\n",
    "print(f\"Total number of attributes with Low Variance : {len(low_var_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aee348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Low Variance attributes from X_train and X_test.\n",
    "\n",
    "X_train = X_train.drop(low_var_cols, axis=1)\n",
    "\n",
    "X_test = X_test.drop(low_var_cols, axis=1)\n",
    "\n",
    "print(f\"Shape of dataframe after removing the low variance columns : {X_train.shape}\")\n",
    "print()\n",
    "print(f\"Shape of dataframe after removing the low variance columns : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b0253",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da09e0",
   "metadata": {},
   "source": [
    "### 6.2 Forward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fe46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the linear regression model for model1.\n",
    "\n",
    "lreg = LinearRegression()\n",
    "sfs1 = sfs(lreg, k_features='best', forward=True, verbose=2, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Sequential Feature Selector.\n",
    "\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the names of the selected features after the fitting process.\n",
    "\n",
    "feat_names1 = list(sfs1.k_feature_names_)\n",
    "feat_names1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selected feature names for separation\n",
    "selected_features = feat_names1\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "X_train_all_best = X_train[selected_features]\n",
    "X_test_all_best = X_test[selected_features]\n",
    "\n",
    "# Display the shape of the new DataFrame to confirm the selection\n",
    "# Print the predicted values\n",
    "display(X_train_all_best.shape)\n",
    "display(X_test_all_best.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54866a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the linear regression model\n",
    "\n",
    "lreg = LinearRegression()\n",
    "sfs2 = sfs(lreg, k_features=6, forward=True, verbose=2, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Sequential Feature Selector.\n",
    "\n",
    "sfs2 = sfs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the names of the selected features after the fitting process.\n",
    "\n",
    "feat_names2 = list(sfs2.k_feature_names_)\n",
    "feat_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99840d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selected feature names for separation\n",
    "selected_features = feat_names2\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "X_train_6_best = X_train[selected_features]\n",
    "X_test_6_best = X_test[selected_features]\n",
    "\n",
    "# Display the shape of the new DataFrame to confirm the selection\n",
    "# Print the predicted values\n",
    "display(X_train_6_best.shape)\n",
    "display(X_test_6_best.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the linear regression model\n",
    "\n",
    "lreg = LinearRegression()\n",
    "sfs3 = sfs(lreg, k_features=4, forward=True, verbose=2, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Sequential Feature Selector.\n",
    "\n",
    "sfs3 = sfs3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f855c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the names of the selected features after the fitting process.\n",
    "\n",
    "feat_names3 = list(sfs3.k_feature_names_)\n",
    "feat_names3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selected feature names for separation\n",
    "selected_features = feat_names3\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "X_train_4_best = X_train[selected_features]\n",
    "X_test_4_best = X_test[selected_features]\n",
    "\n",
    "# Display the shape of the new DataFrame to confirm the selection\n",
    "# Print the predicted values\n",
    "display(X_train_4_best.shape)\n",
    "display(X_test_4_best.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703566e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shapes of the final resulting datasets before training the models.\n",
    "\n",
    "print(\"All best features Training dataset shapes ->  X: {}, y: {}\".format(X_train_all_best.shape, y_train.shape))\n",
    "print(\"All best features Testing dataset shapes  ->  X: {}, y: {}\".format(X_test_all_best.shape, y_test.shape))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Top 6 best features Training dataset shapes ->  X: {}, y: {}\".format(X_train_6_best.shape, y_train.shape))\n",
    "print(\"Top 6 best features Testing dataset shapes  ->  X: {}, y: {}\".format(X_test_6_best.shape, y_test.shape))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Top 4 best features Training dataset shapes ->  X: {}, y: {}\".format(X_train_4_best.shape, y_train.shape))\n",
    "print(\"Top 4 best features Testing dataset shapes  ->  X: {}, y: {}\".format(X_test_4_best.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c8991",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e98308",
   "metadata": {},
   "source": [
    "## 7. Binary Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null error rate \n",
    "\n",
    "count = df[df['TARGET'] == 1]['TARGET'].value_counts().sum()\n",
    "\n",
    "null_error_rate = 1 - (count / df.shape[0])\n",
    "\n",
    "print(f'Null Error Rate:',null_error_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770769de",
   "metadata": {},
   "source": [
    "- The null error rate of  to see whether the accuracy we  are attaining exceeds the null error rate. If not, our  model is unlikely to be of any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33127a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the balance of Actual Data class of y_train.\n",
    "display(np.unique(y_train, return_counts=True))\n",
    "\n",
    "print(5598 / len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727f126",
   "metadata": {},
   "source": [
    "- Actual Data class of y_train is imbalance (72-28)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f57497",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b7ab9",
   "metadata": {},
   "source": [
    "### 7.1 1<sup>st</sup> Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Logistic Regression from the sklearn library into a variable and train.\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "model1.fit(X_train_all_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad554e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the different matrix of the model1 to the training data set using k-fold.\n",
    "\n",
    "# 10 k-fold splits for training dataset\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# k-fold cross validation.\n",
    "\n",
    "accuracy = cross_val_score(model1, X_train_all_best, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy of training dataset : {accuracy}\")\n",
    "print()\n",
    "print(f\"Accuracy of training dataset : {np.mean(accuracy)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "precision = cross_val_score(model1, X_train_all_best, y_train, cv=kf, scoring='precision')\n",
    "\n",
    "print(f\"Precision of training dataset : {precision}\")\n",
    "print()\n",
    "print(f\"Precision of training dataset : {np.mean(precision)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "recall = cross_val_score(model1, X_train_all_best, y_train, cv=kf, scoring='recall')\n",
    "\n",
    "print(f\"Recall of training dataset : {recall}\")\n",
    "print()\n",
    "print(f\"Recall of training dataset : {np.mean(recall)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "f1 = cross_val_score(model1, X_train_all_best, y_train, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"F1 scores of training dataset : {f1}\")\n",
    "print()\n",
    "print(f\"F1 score of training dataset : {np.mean(f1)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "roc_auc = cross_val_score(model1, X_train_all_best, y_train, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Roc-Auc scores of training dataset : {roc_auc}\")\n",
    "print()\n",
    "print(f\"Roc-Auc score of training dataset : {np.mean(roc_auc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the model1 coefficients.\n",
    "\n",
    "print(feat_names1)\n",
    "model1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b97c3",
   "metadata": {},
   "source": [
    "- Features such as age, LOR, turnover_A, and turnover_B show a positive coefficient, implying that as the values of these features increase, the probability or magnitude of the TARGET variable also increases. This indicates a higher likelihood of a customer purchasing a new product.\n",
    "\n",
    "- For example, when a customer's age is higher, they may be more inclined to buy a new product, such as health or vehicle insurance. The same logic applies to turnovers if a customer contributes a high turnover, it increases the likelihood of purchasing a new product, as this suggests the customer trusts the insurance company.\n",
    "\n",
    "- Looking at the features with negative coefficients, such as type_A_3 and Prod_B_1, it implies that as the count of type_3 products of A increases, the likelihood of a customer purchasing a new product decreases. The same scenario applies to Prod_B_1, where an increase in the count reduces the probability of a new product purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366dfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for training set of model1.\n",
    "\n",
    "X_train_prob_all_best = model1.predict_proba(X_train_all_best)[:, 1] \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, X_train_prob_all_best) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for MODEL 1 (Training set)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1428a43",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd8d4e",
   "metadata": {},
   "source": [
    "### 7.2 2<sup>nd</sup> Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Logistic Regression from the sklearn library into a variable and train.\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "\n",
    "model2.fit(X_train_6_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26707fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the different matrix of the model2 to the training data set using k-fold.\n",
    "\n",
    "# 10 k-fold splits for training dataset\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# k-fold cross validation.\n",
    "\n",
    "accuracy = cross_val_score(model2, X_train_6_best, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy of training dataset : {accuracy}\")\n",
    "print()\n",
    "print(f\"Accuracy of training dataset : {np.mean(accuracy)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "precision = cross_val_score(model2, X_train_6_best, y_train, cv=kf, scoring='precision')\n",
    "\n",
    "print(f\"Precision of training dataset : {precision}\")\n",
    "print()\n",
    "print(f\"Precision of training dataset : {np.mean(precision)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "recall = cross_val_score(model2, X_train_6_best, y_train, cv=kf, scoring='recall')\n",
    "\n",
    "print(f\"Recall of training dataset : {recall}\")\n",
    "print()\n",
    "print(f\"Recall of training dataset : {np.mean(recall)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "f1 = cross_val_score(model2, X_train_6_best, y_train, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"F1 scores of training dataset : {f1}\")\n",
    "print()\n",
    "print(f\"F1 score of training dataset : {np.mean(f1)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "roc_auc = cross_val_score(model2, X_train_6_best, y_train, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Roc-Auc scores of training dataset : {roc_auc}\")\n",
    "print()\n",
    "print(f\"Roc-Auc score of training dataset : {np.mean(roc_auc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the model2 coefficients.\n",
    "\n",
    "print(feat_names2)\n",
    "model2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22225902",
   "metadata": {},
   "source": [
    "- Observing the coefficients, they are all positive except for Prod_B_1, which means that as the value of these features increases, the magnitude of the response variable, in this case, the 'TARGET', will also increase.\n",
    "\n",
    "- Turnover_A and turnover_B have positive coefficients, which implies that as these increase, the chances of a customer buying a product also increase.\n",
    "\n",
    "- When a customer's age is higher, they may be more inclined to buy a new product, such as health or vehicle insurance.\n",
    "\n",
    "- For Prod_B_1, since it has a negative coefficient, the likelihood of a customer purchasing a new product decreases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for training set of model2.\n",
    "\n",
    "X_train_prob_6_best = model2.predict_proba(X_train_6_best)[:, 1] \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, X_train_prob_6_best) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for MODEL 2 (Training set)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292b31a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ea3f0",
   "metadata": {},
   "source": [
    "### 7.3 3<sup>rd</sup> Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Logistic Regression from the sklearn library into a variable and train.\n",
    "\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model3.fit(X_train_4_best, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the different matrix of the model2 to the training data set using k-fold.\n",
    "\n",
    "# 10 k-fold splits for training dataset\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# k-fold cross validation.\n",
    "\n",
    "accuracy = cross_val_score(model3, X_train_4_best, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy of training dataset : {accuracy}\")\n",
    "print()\n",
    "print(f\"Accuracy of training dataset : {np.mean(accuracy)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "precision = cross_val_score(model3, X_train_4_best, y_train, cv=kf, scoring='precision')\n",
    "\n",
    "print(f\"Precision of training dataset : {precision}\")\n",
    "print()\n",
    "print(f\"Precision of training dataset : {np.mean(precision)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "recall = cross_val_score(model3, X_train_4_best, y_train, cv=kf, scoring='recall')\n",
    "\n",
    "print(f\"Recall of training dataset : {recall}\")\n",
    "print()\n",
    "print(f\"Recall of training dataset : {np.mean(recall)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "f1 = cross_val_score(model3, X_train_4_best, y_train, cv=kf, scoring='f1')\n",
    "\n",
    "print(f\"F1 scores of training dataset : {f1}\")\n",
    "print()\n",
    "print(f\"F1 score of training dataset : {np.mean(f1)}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "roc_auc = cross_val_score(model3, X_train_4_best, y_train, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Roc-Auc scores of training dataset : {roc_auc}\")\n",
    "print()\n",
    "print(f\"Roc-Auc score of training dataset : {np.mean(roc_auc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bf246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the model3 coefficients.\n",
    "\n",
    "print(feat_names3)\n",
    "model3.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb3998",
   "metadata": {},
   "source": [
    "- In these features, except for Prod_B_1, all of the other features have positive coefficients, which means that as the values of these explanatory variables increase, the magnitude of the TARGET also increases.\n",
    "\n",
    "- When a customer's age is higher, they may be more inclined to buy a new product, such as health or vehicle insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d13a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for training set of model3.\n",
    "\n",
    "X_train_prob_4_best = model3.predict_proba(X_train_4_best)[:, 1] \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, X_train_prob_4_best) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for MODEL 3 (Training set)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e954399d",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555abda6",
   "metadata": {},
   "source": [
    "## 8. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569e982",
   "metadata": {},
   "source": [
    "- As per the above different measuring parameters, we have selected the model-2 as our best model.\n",
    "\n",
    "- Among all three models' parameter of the training set - Accuracy, Precision, Recall, F1 scores, Roc-Auc scores have almost model1 & model2 are approximatly same with very minute difference, whereas model3 has least. Thus, with less number of attributes model2 is giving almost similar result as of model1(with greater number of attrributes).\n",
    "\n",
    "- Now, we will predict as per the training for the test of our selected model-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ab628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the balance of Actual Data class of y_test.\n",
    "display(np.unique(y_test, return_counts=True))\n",
    "\n",
    "print(2402 / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5df41f",
   "metadata": {},
   "source": [
    "- Actual Data class of y_test is imbalance (72-28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for the test data for 6 best.\n",
    "\n",
    "y_pred_6_best = model2.predict(X_test_6_best)\n",
    "y_pred_6_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5fa99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Confusion Matrix using crosstab() function and display it.\n",
    "\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred_6_best, rownames=['actual'], colnames=['predicted'])\n",
    "print('\\033[1m-: Confusion Matrix :-\\033[0m')\n",
    "display(confusion_matrix.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ffa61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # To print the different parameters on the basis of confusion matrix.\n",
    "\n",
    "def model_parameters():  \n",
    "    \n",
    "    print('\\033[1mFinal Model Parameters:- \\033[0m')\n",
    "    print()\n",
    "\n",
    "    # To print Accuracy.\n",
    "    print('\\033[1mAccuracy : \\033[0m', round(metrics.accuracy_score(list(y_test), list(y_pred_6_best)), 3))\n",
    "    print()\n",
    "\n",
    "    # To print Precision.\n",
    "    print('\\033[1mPrecision : \\033[0m', round(metrics.precision_score(list(y_test), list(y_pred_6_best)), 3))\n",
    "    print()\n",
    "\n",
    "    # To print Sensitivity.\n",
    "    print('\\033[1mSensitivity : \\033[0m', round(metrics.recall_score(list(y_test), list(y_pred_6_best)), 3))\n",
    "    print()\n",
    "\n",
    "    # To print Specificity.\n",
    "    print('\\033[1mSpecificity : \\033[0m', round(imblearn.metrics.specificity_score(list(y_test), \n",
    "                                                                                   list(y_pred_6_best)), 3))\n",
    "    print()\n",
    "\n",
    "    # To print F1 Score.\n",
    "    print('\\033[1mF1 Score : \\033[0m', round(metrics.f1_score(list(y_test), list(y_pred_6_best)), 3))\n",
    "    print()\n",
    "    \n",
    "model_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf69dd",
   "metadata": {},
   "source": [
    "- `Accuracy(81.2%)` - It means that 81.2% of times our model predicts correctly, but the distribution of 1's and 0's of actual class is approx 70-30. So, we have imblanced dataset, therefore it is not a good metric for any judgement.\n",
    "\n",
    "- `Precision(70.7%)` - It’s correct about 70.7% of the time, so it’s decent at avoiding false positives(that is wrongly predicting the positive class when it should be negative).\n",
    "\n",
    "- `Sensitivity(52.9%)` - It means that our model only catches about 52.9% of the actual positive cases, means it misses a lot of true positives.\n",
    "\n",
    "- `Specificity(91.8%)` - Our model is great at identifying the negatives, correctly classifying about 92% of non-positive cases.\n",
    "\n",
    "- `F1 Score(60.5%)` - This shows an overall balance between precision and recall is averageof about 60.5%, suggesting our model is troubling with consistently identifying positive cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve for training set of model.\n",
    "\n",
    "y_pred_prob = model2.predict_proba(X_test_6_best)[:, 1] \n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for selected MODEL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58709ff7",
   "metadata": {},
   "source": [
    "- AUC of 0.84 indicates that our model is performing well in distinguishing between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c2461",
   "metadata": {},
   "source": [
    "__RESULT__\n",
    "\n",
    "- Our model is good at avoiding false positives but it misses many true positives, so it needs improvement in capturing those positive cases without compromising its strong negative predictions. \n",
    "- Therefore, our model has high specificity and nice precision, which means it performs well at minimizing false positives and classifying negative cases. \n",
    "- Though, we can enhance our model's ability to detect more positive cases by reevaluting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b04ad3b",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<b> [Back to Content](#Content) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a8cef",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee11560",
   "metadata": {},
   "source": [
    "1. The dataset has 3008 duplicate values.\n",
    "\n",
    "2. These columns were non predictive in training model (ID,age_p,loyalty,city,lor_m,contract)\n",
    "\n",
    "3. Loyalty column has 45% of unclassified values('99') in it.\n",
    "\n",
    "4. 'Length of relationship' has strong or positive correlation with 'Age' columns.\n",
    "\n",
    "5. We have selected the model on the basis of following metrices:-\n",
    "   a. Accuracy - 81.2%\n",
    "   b. Precision - 70.7%\n",
    "   c. Sensitivity - 52.9%\n",
    "   d. AUC - 0.84\n",
    "   e. Specificity - 91.8%\n",
    "   f. F1 Score - 60.5%\n",
    "   \n",
    "6. To increase customer retention and improve insurance sales, focusing on improving recall would help capture more potential buyers.\n",
    "\n",
    "7. Improving recall will help the company reach more customers who might be interested in buying extra insurance plans, even if it means also reaching some customers who might not buy anything. Finding the right balance between precision and recall, shown by an F1 score of 60.5%, is important for increasing insurance sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d69bf3",
   "metadata": {},
   "source": [
    "<b> [TOP⬆️](#Classification-via-KNN-&-SVM) </b>\n",
    "\n",
    "---\n",
    "<h3><center>THE END</center></h3>\n",
    "\n",
    "==================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf9ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
